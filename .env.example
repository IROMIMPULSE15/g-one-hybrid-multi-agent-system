# ==================== DATABASE ====================
# For local development: mongodb://localhost:27017/g-one
# For production: Use MongoDB Atlas connection string
MONGODB_URI=mongodb://localhost:27017/g-one

# ==================== AUTHENTICATION ====================
# Generate a secure secret: openssl rand -base64 32
NEXTAUTH_SECRET=your-secret-key-here-change-this-in-production
# For local: http://localhost:3000
# For production: https://your-domain.vercel.app
NEXTAUTH_URL=http://localhost:3000

# Google OAuth (https://console.cloud.google.com)
GOOGLE_CLIENT_ID=your-google-client-id.apps.googleusercontent.com
GOOGLE_CLIENT_SECRET=your-google-client-secret

# ==================== PAYMENT ====================
# Stripe Keys (https://dashboard.stripe.com/apikeys)
# Use test keys for development (pk_test_..., sk_test_...)
# Use live keys for production (pk_live_..., sk_live_...)
STRIPE_PUBLIC_KEY=pk_test_your_key_here
STRIPE_SECRET_KEY=sk_test_your_key_here

# ==================== LLM PROVIDERS ====================
# Primary LLM Provider: ollama | openai | gemini | llama
LLM_PROVIDER=ollama

# Ollama Configuration (for local development with Llama3)
# For local: http://localhost:11434
# For production: Host Ollama on a separate server (Railway, Render, VPS, etc.)
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b

# OpenAI Configuration (Fallback or Primary)
OPENAI_API_KEY=sk-your-openai-key-here
OPENAI_MODEL=gpt-4o-mini

# Google Gemini Configuration (Fallback or Primary)
GEMINI_API_KEY=your-gemini-api-key-here
GEMINI_MODEL=gemini-2.0-flash-exp

# Hugging Face Configuration (Optional)
HUGGINGFACE_API_KEY=hf_your-huggingface-key-here
LLAMA_MODEL=mistralai/Mistral-7B-Instruct-v0.2

# ==================== VECTOR DATABASE ====================
# Pinecone Configuration (https://www.pinecone.io/)
PINECONE_API_KEY=your-pinecone-api-key-here
PINECONE_INDEX_NAME=medical-embeddings
PINECONE_INDEX=voice-assistant-knowledge

# ==================== APP CONFIGURATION ====================
# Environment: development | production | test
NODE_ENV=development

# App Name
NEXT_PUBLIC_APP_NAME=G-One AI

# API Base URL
# For local: http://localhost:3000/api
# For production: https://your-domain.vercel.app/api
NEXT_PUBLIC_API_BASE=http://localhost:3000/api

# ==================== OPTIONAL SERVICES ====================
# Sentry (Error Tracking) - https://sentry.io/
SENTRY_DSN=your-sentry-dsn-here
SENTRY_AUTH_TOKEN=your-sentry-auth-token-here

# Google Analytics
NEXT_PUBLIC_GA_ID=your-google-analytics-id-here

# ==================== NOTES ====================
# 1. Copy this file to .env and fill in your actual values
# 2. Never commit .env to version control
# 3. For production deployment on Vercel:
#    - Set all these variables in Vercel Dashboard > Settings > Environment Variables
#    - Update URLs to use your production domain
#    - Use production API keys (Stripe live keys, etc.)
#    - Host Ollama separately if using it in production